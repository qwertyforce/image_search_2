{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import splitext\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pickle as pk\n",
    "from tqdm import tqdm\n",
    "\n",
    "IMAGES_PATH=\"./../images\"\n",
    "def read_img_file(f):\n",
    "    img = Image.open(f)\n",
    "    # img=img.convert('L').convert('RGB') #GREYSCALE\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    return img\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = timm.create_model('beit_base_patch16_224_in22k', pretrained=True)\n",
    "\n",
    "# model.global_pool=timm.models.layers.SelectAdaptivePool2d(pool_type=\"max\", flatten=True) # for resnet models (cant remember which one, sry :(  )\n",
    "# model.fc=nn.Identity()\n",
    "\n",
    "model.head=nn.Identity()\n",
    "\n",
    "# model.head.global_pool=timm.models.layers.SelectAdaptivePool2d(pool_type=\"max\", flatten=True) # for resnet models (cant remember which one, sry :(  )\n",
    "# model.head.fc=nn.Identity()\n",
    "# model.head.flatten=nn.Identity()\n",
    "# print(model)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "IMAGENET_DEFAULT_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_DEFAULT_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "IMAGENET_DEFAULT_MEAN_21k = [0.5, 0.5, 0.5]\n",
    "IMAGENET_DEFAULT_STD_21k = [0.5, 0.5, 0.5]\n",
    "\n",
    "_transform=transforms.Compose([\n",
    "                       transforms.Resize((224,224)),\n",
    "                      #  transforms.CenterCrop(224),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize(IMAGENET_DEFAULT_MEAN_21k,IMAGENET_DEFAULT_STD_21k)])\n",
    "\n",
    "\n",
    "def transform(im):\n",
    "  return _transform(im)\n",
    "# def transform(im):\n",
    "#   desired_size = 224\n",
    "#   old_size = im.size  # old_size[0] is in (width, height) format\n",
    "#   ratio = float(desired_size)/max(old_size)\n",
    "#   new_size = tuple([int(x*ratio) for x in old_size])\n",
    "#   im = im.resize(new_size, Image.ANTIALIAS)\n",
    "#   new_im = Image.new(\"RGB\", (desired_size, desired_size))\n",
    "#   new_im.paste(im, ((desired_size-new_size[0])//2, (desired_size-new_size[1])//2))\n",
    "#   return _transform(new_im)\n",
    "\n",
    "first_img=True\n",
    "def get_features(f):\n",
    "    global first_img\n",
    "    img = read_img_file(f)\n",
    "    image = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        image_features = model(image).cpu().numpy()[0]\n",
    "    # print(first_img)\n",
    "    if first_img:\n",
    "      first_img=False\n",
    "      print(image_features.shape)\n",
    "    return image_features\n",
    "\n",
    "\n",
    "def generate_resnet_features():\n",
    "    image_filenames=listdir(IMAGES_PATH)\n",
    "    image_filenames.sort()\n",
    "    # image_ids=set(map(lambda el: splitext(el)[0],image_filenames))\n",
    "    image_filenames_batches = [image_filenames[i:i + 100000] for i in range(0, len(image_filenames), 100000)]\n",
    "    batch_num=1\n",
    "    for batch in image_filenames_batches:\n",
    "      save_path = f\"./beit_fips_224x224_color_{batch_num*100}k.pkl\"\n",
    "      if os.path.exists(save_path):\n",
    "         print(f\"{save_path} exists, skipping\")\n",
    "         batch_num+=1\n",
    "         continue\n",
    "      all_image_features=[]\n",
    "      for image_filename in tqdm(batch):\n",
    "          image_id=splitext(image_filename)[0]\n",
    "          try:\n",
    "            image_features=get_features(IMAGES_PATH+\"/\"+image_filename)\n",
    "            all_image_features.append({'image_id':image_id,'features':image_features})\n",
    "          except:\n",
    "            print(\"something is wrong!!!\",image_filename)\n",
    "            pass\n",
    "          # print(image_features.dtype)\n",
    "      pk.dump(all_image_features, open(save_path,\"wb\"))\n",
    "      batch_num+=1\n",
    "\n",
    "generate_resnet_features()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
